{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Data Exploration, Preprocessing, and Heuristic Labeling\n",
    "\n",
    "This notebook covers the initial steps of loading example CPAP data, performing preprocessing, detecting breaths and events, and then applying a heuristic (rule-based) labeling approach to a subset of events. This labeled subset will serve as the initial 'ground truth' for training our classification model.\n",
    "\n",
    "**Assumed File Structure:**\n",
    "```\n",
    "repository_root/\n",
    "├── data/\n",
    "│   └── test_data_merged_10min.parquet  # Example Parquet data file in root\n",
    "├── notebooks/\n",
    "│   └── 01_Initial_Data_Exploration_and_Labeling.ipynb\n",
    "├── src/\n",
    "│   ├── data_loader.py\n",
    "│   ├── preprocessing.py\n",
    "│   ├── breath_detection.py\n",
    "│   ├── event_detection.py\n",
    "│   └── feature_engineering.py\n",
    "│   └── classification_model.py\n",
    "└── results/\n",
    "    └── (plots, outputs will be saved here)\n",
    "```\n",
    "\n",
    "**Note:** This notebook now attempts to load `test_data_merged_10min.parquet` from the project root. The dummy CSV generation code is removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path to import modules\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assumes notebook is in 'notebooks' directory\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data_loader import load_parquet_data, resample_data # Updated to include load_parquet_data\n",
    "from src.preprocessing import butterworth_filter, flag_high_leak_periods, calculate_rolling_baseline\n",
    "from src.breath_detection import detect_breaths_from_flow\n",
    "from src.event_detection import detect_apneas_hypopneas\n",
    "from src.feature_engineering import extract_features_for_event\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Parquet file path and column mapping\n",
    "PARQUET_FILE_PATH = '../test_data_merged_10min.parquet' # Path relative to 'notebooks' directory\n",
    "EXPECTED_SAMPLING_FREQ_HZ = 25 # Hz, based on 'Flow.40ms'\n",
    "\n",
    "COLUMN_MAP = {\n",
    "    'flow_rate': 'Flow.40ms',\n",
    "    'pressure': 'Press.2s', \n",
    "    'mask_pressure': 'MaskPress.2s',\n",
    "    'epr_pressure': 'EprPress.2s',\n",
    "    'leak_rate': 'Leak.2s',\n",
    "    'respiratory_rate': 'RespRate.2s',\n",
    "    'minute_ventilation': 'MinVent.2s',\n",
    "    'flow_limitation': 'FlowLim.2s'\n",
    "}\n",
    "\n",
    "# Load data using the load_parquet_data function\n",
    "raw_df = load_parquet_data(filepath=PARQUET_FILE_PATH,\n",
    "                           timestamp_col_name_in_file='timestamp', # Parquet has index named 'timestamp'\n",
    "                           standard_timestamp_col='timestamp',\n",
    "                           column_name_map=COLUMN_MAP)\n",
    "\n",
    "if raw_df is not None:\n",
    "    print(\"Parquet data loaded successfully:\")\n",
    "    raw_df.info()\n",
    "    print(\"\\nData Head:\")\n",
    "    print(raw_df.head())\n",
    "\n",
    "    # --- Data Scaling Consideration ---\n",
    "    # The 'Flow.40ms' data is scaled (e.g. values like 600,000+).\n",
    "    # For physiological interpretation and some fixed thresholds (if any), rescaling is often useful.\n",
    "    # Let's assume a scaling factor (e.g., divide by 1000 if it's mL/s, or by 60000 if mL/min to L/s)\n",
    "    # This factor needs to be determined based on known properties of the data source.\n",
    "    # For now, we'll apply a hypothetical scaling factor for demonstration.\n",
    "    HYPOTHETICAL_SCALE_FACTOR = 1000.0 # Example: if original data was in mL/s and we want L/s\n",
    "    if 'flow_rate' in raw_df.columns and raw_df['flow_rate'].abs().mean() > 100: # Heuristic for scaled data\n",
    "        print(f\"\\nOriginal flow_rate scale (mean abs): {raw_df['flow_rate'].abs().mean():.2f}\")\n",
    "        raw_df['flow_rate'] = raw_df['flow_rate'] / HYPOTHETICAL_SCALE_FACTOR\n",
    "        print(f\"Flow_rate rescaled by dividing by {HYPOTHETICAL_SCALE_FACTOR}.\")\n",
    "        print(f\"New flow_rate scale (mean abs): {raw_df['flow_rate'].abs().mean():.2f}\")\n",
    "    # Similar rescaling might be needed for other columns if they are also scaled (e.g. pressure, volume)\n",
    "    # For now, only applying to flow_rate as its scale is most obviously non-physiological in example.\n",
    "else:\n",
    "    print(f\"Failed to load Parquet data from {PARQUET_FILE_PATH}.\")\n",
    "    # Create an empty DataFrame to prevent errors in subsequent cells if loading fails\n",
    "    raw_df = pd.DataFrame(columns=list(COLUMN_MAP.keys())) \n",
    "    raw_df.index = pd.to_datetime([])\n",
    "    raw_df.index.name = 'timestamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Resampling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use EXPECTED_SAMPLING_FREQ_HZ as the target for resampling if needed, \n",
    "# or verify if data is already at this frequency.\n",
    "TARGET_SAMPLING_FREQ_HZ = EXPECTED_SAMPLING_FREQ_HZ \n",
    "\n",
    "if raw_df is not None and not raw_df.empty:\n",
    "    # Check current sampling frequency if possible\n",
    "    current_sf = 0\n",
    "    if len(raw_df.index) > 1:\n",
    "        median_diff_s = raw_df.index.to_series().diff().median().total_seconds()\n",
    "        if median_diff_s > 0:\n",
    "            current_sf = 1.0 / median_diff_s\n",
    "            print(f\"Detected median sampling frequency: {current_sf:.2f} Hz\")\n",
    "    \n",
    "    if current_sf != TARGET_SAMPLING_FREQ_HZ and current_sf != 0:\n",
    "        print(f\"Resampling data to {TARGET_SAMPLING_FREQ_HZ} Hz...\")\n",
    "        df_processed = resample_data(raw_df, target_freq_hz=TARGET_SAMPLING_FREQ_HZ)\n",
    "    else:\n",
    "        print(\"Data is already at the target sampling frequency or frequency detection failed; using as is.\")\n",
    "        df_processed = raw_df.copy() # Use the (potentially rescaled) raw_df directly\n",
    "    \n",
    "    if df_processed is not None and not df_processed.empty:\n",
    "        print(f\"\\nData ready for preprocessing (target {TARGET_SAMPLING_FREQ_HZ} Hz):\")\n",
    "        df_processed.info()\n",
    "        \n",
    "        # Ensure required columns exist before trying to use them\n",
    "        required_cols_for_processing = ['flow_rate', 'leak_rate', 'pressure']\n",
    "        if not all(col in df_processed.columns for col in required_cols_for_processing):\n",
    "            print(f\"Error: Missing one or more required columns for preprocessing: {required_cols_for_processing}\")\n",
    "            print(f\"Available columns: {df_processed.columns.tolist()}\")\n",
    "        else:\n",
    "            df_processed['flow_rate_filtered'] = butterworth_filter(\n",
    "                df_processed['flow_rate'], \n",
    "                filter_type='lowpass', \n",
    "                cutoff_freq_hz=3.0, # Adjusted for potentially real data\n",
    "                sampling_freq_hz=TARGET_SAMPLING_FREQ_HZ,\n",
    "                order=2 # Gentler filter\n",
    "            )\n",
    "            \n",
    "            df_processed['high_leak'] = flag_high_leak_periods(\n",
    "                df_processed['leak_rate'], \n",
    "                leak_threshold=24.0, # Standard ResMed leak threshold L/min\n",
    "                min_duration_sec=10.0, \n",
    "                sampling_freq_hz=TARGET_SAMPLING_FREQ_HZ\n",
    "            )\n",
    "            \n",
    "            df_processed['flow_baseline'] = calculate_rolling_baseline(\n",
    "                df_processed['flow_rate_filtered'].abs(), \n",
    "                window_sec=120, \n",
    "                sampling_freq_hz=TARGET_SAMPLING_FREQ_HZ,\n",
    "                quantile=0.5 # Median\n",
    "            )\n",
    "            \n",
    "            print(\"\\nPreprocessed data head:\")\n",
    "            print(df_processed[['flow_rate', 'flow_rate_filtered', 'flow_baseline', 'high_leak']].head())\n",
    "            \n",
    "            # Plot to verify\n",
    "            plt.figure(figsize=(15, 8))\n",
    "            ax1 = plt.subplot(211)\n",
    "            df_processed['flow_rate'].plot(label='Flow (Rescaled if needed)', alpha=0.7, ax=ax1)\n",
    "            df_processed['flow_rate_filtered'].plot(label='Filtered Flow', ax=ax1)\n",
    "            df_processed['flow_baseline'].plot(label='Flow Baseline (Abs Median)', linestyle='--', ax=ax1)\n",
    "            ax1.set_title('Flow Data and Baseline')\n",
    "            ax1.legend()\n",
    "            \n",
    "            ax2 = plt.subplot(212, sharex=ax1)\n",
    "            df_processed['leak_rate'].plot(label='Leak Rate', ax=ax2)\n",
    "            ax2.fill_between(df_processed.index, 0, df_processed['leak_rate'].max(), \n",
    "                             where=df_processed['high_leak'], color='red', alpha=0.3, label='High Leak Period')\n",
    "            ax2.set_title('Leak Data')\n",
    "            ax2.legend()\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"Data processing failed or resulted in empty DataFrame.\")\n",
    "        df_processed = pd.DataFrame() # Ensure it's defined for next cells\n",
    "else:\n",
    "    print(\"Skipping preprocessing as data loading failed or raw_df is empty.\")\n",
    "    df_processed = pd.DataFrame() # Ensure it's defined for next cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Breath and Event Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_processed' in locals() and df_processed is not None and not df_processed.empty:\n",
    "    # Breath Detection (Optional - mainly for EDA or if features depend on it)\n",
    "    # Note: detect_breaths_from_flow has adaptive thresholds. \n",
    "    # Pass None for hysteresis/prominence or values appropriate for the (potentially rescaled) flow.\n",
    "    # breaths_df = detect_breaths_from_flow(df_processed['flow_rate_filtered'], \n",
    "    #                                       sampling_freq_hz=TARGET_SAMPLING_FREQ_HZ,\n",
    "    #                                       zero_crossing_hysteresis=None, \n",
    "    #                                       peak_prominence_threshold=None)\n",
    "    # if not breaths_df.empty:\n",
    "    #     print(f\"\\nDetected {len(breaths_df)} breaths.\")\n",
    "    #     # print(breaths_df.head())\n",
    "    # else:\n",
    "    #     print(\"No breaths detected.\")\n",
    "        \n",
    "    # Event Detection\n",
    "    # Ensure all required columns for event detection are present and correctly named\n",
    "    if all(col in df_processed.columns for col in ['flow_rate_filtered', 'flow_baseline', 'high_leak']):\n",
    "        events_df = detect_apneas_hypopneas(\n",
    "            flow_series=df_processed['flow_rate_filtered'],\n",
    "            baseline_flow_series=df_processed['flow_baseline'],\n",
    "            sampling_freq_hz=TARGET_SAMPLING_FREQ_HZ,\n",
    "            apnea_threshold_ratio=0.1, \n",
    "            hypopnea_upper_threshold_ratio=0.7, \n",
    "            hypopnea_lower_threshold_ratio=0.1, \n",
    "            min_event_duration_s=10.0,\n",
    "            high_leak_flags=df_processed['high_leak']\n",
    "        )\n",
    "    \n",
    "        if not events_df.empty:\n",
    "            print(f\"\\nDetected {len(events_df)} apnea/hypopnea candidate events:\")\n",
    "            print(events_df[['event_start_time', 'event_end_time', 'event_type', 'event_duration_s', 'avg_flow_reduction_percent', 'excluded_due_to_leak']].head())\n",
    "        else:\n",
    "            print(\"No apnea/hypopnea events detected.\")\n",
    "            events_df = pd.DataFrame() # Ensure it exists for later steps\n",
    "    else:\n",
    "        print(\"Error: Missing columns required for event detection in df_processed.\")\n",
    "        events_df = pd.DataFrame()\n",
    "\n",
    "else:\n",
    "    print(\"Skipping event detection as preprocessing failed or was skipped, or df_processed is empty.\")\n",
    "    events_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Heuristic Labeling of Events\n",
    "\n",
    "Now, we'll define some heuristic rules to assign initial labels ('likely_obstructive', 'likely_central', 'ambiguous') to the detected events. This requires visual inspection and domain knowledge. We'll create a helper function to plot events for inspection.\n",
    "\n",
    "**Heuristic Ideas (examples, needs refinement based on data):**\n",
    "*   **Likely Obstructive:**\n",
    "    *   Apnea/Hypopnea with significant flow flattening *before* or *during* (for hypopnea) - requires feature engineering.\n",
    "    *   Sharp, large recovery breaths immediately following the event - requires feature engineering.\n",
    "    *   Associated with increased pressure from an auto-CPAP (if pressure data shows this clearly).\n",
    "    *   High variability in flow leading up to an apnea - requires feature engineering.\n",
    "*   **Likely Central:**\n",
    "    *   Smooth, tapered decrease and increase in flow for apneas.\n",
    "    *   Often part of a periodic breathing pattern (e.g., Cheyne-Stokes like waxing/waning flow over longer periods) - requires feature engineering.\n",
    "    *   Hypopneas show proportional reduction in flow without significant shape change (inspiratory flow still rounded) - requires feature engineering.\n",
    "    *   No significant auto-CPAP pressure increase specifically for the event.\n",
    "*   **Ambiguous:** Events that don't clearly fit either pattern or have conflicting features.\n",
    "\n",
    "**Note on Heuristics for this Notebook:** The example heuristics below are simplified and may use properties of the dummy data generation. For real data, these rules need to be carefully developed by inspecting plots and potentially using features from `feature_engineering.py` in an iterative process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_for_labeling(event_idx, event_series, flow_signal, pressure_signal, baseline_signal, window_s=30):\n",
    "    \"\"\"Plots flow and pressure around an event for manual inspection and labeling.\"\"\"\n",
    "    event_start = event_series['event_start_time']\n",
    "    event_end = event_series['event_end_time']\n",
    "    event_type = event_series['event_type']\n",
    "    \n",
    "    # Ensure signals are not empty and window is valid\n",
    "    if flow_signal.empty or pressure_signal.empty:\n",
    "        print(f\"Warning: Flow or pressure signal is empty for event {event_idx}. Cannot plot.\")\n",
    "        return\n",
    "        \n",
    "    plot_start = event_start - pd.Timedelta(seconds=window_s)\n",
    "    plot_end = event_end + pd.Timedelta(seconds=window_s)\n",
    "    \n",
    "    # Clip plot_start and plot_end to the signal's range to avoid KeyErrors\n",
    "    plot_start = max(plot_start, flow_signal.index.min())\n",
    "    plot_end = min(plot_end, flow_signal.index.max())\n",
    "    \n",
    "    if plot_start >= plot_end:\n",
    "        print(f\"Warning: Invalid plot window for event {event_idx} after clipping. Cannot plot.\")\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(18, 7))\n",
    "    \n",
    "    # Flow Plot\n",
    "    ax1 = plt.subplot(211)\n",
    "    flow_signal.loc[plot_start:plot_end].plot(label='Flow', ax=ax1, color='cornflowerblue')\n",
    "    if baseline_signal is not None and not baseline_signal.empty:\n",
    "         baseline_signal.loc[plot_start:plot_end].plot(label='Flow Baseline', linestyle='--', color='orange', ax=ax1)\n",
    "    ax1.axvspan(event_start, event_end, color='red', alpha=0.2, label=f'{event_type}')\n",
    "    ax1.set_title(f'Event {event_idx}: {event_type} ({event_series[\"event_duration_s\"]:.1f}s) | Start: {event_start.time()}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "    \n",
    "    # Pressure Plot\n",
    "    ax2 = plt.subplot(212, sharex=ax1)\n",
    "    pressure_signal.loc[plot_start:plot_end].plot(label='Pressure', ax=ax2, color='green')\n",
    "    ax2.axvspan(event_start, event_end, color='red', alpha=0.2)\n",
    "    ax2.set_title('Pressure')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    results_dir = '../results/event_plots_for_labeling'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    plt.savefig(f\"{results_dir}/event_{event_idx}_{event_type.replace('_candidate','')}.png\")\n",
    "    plt.close() \n",
    "\n",
    "# Initialize a new column for heuristic labels\n",
    "if 'events_df' in locals() and not events_df.empty:\n",
    "    events_df['heuristic_label'] = 'ambiguous' # Default\n",
    "    \n",
    "    print(\"\\nPlotting a few events for manual inspection (plots saved to results/event_plots_for_labeling/):\")\n",
    "    num_events_to_plot = min(len(events_df), 5)\n",
    "    for i in range(num_events_to_plot):\n",
    "        event = events_df.iloc[i]\n",
    "        if 'df_processed' in locals() and not df_processed.empty and \\
    "           'flow_rate_filtered' in df_processed.columns and \\
    "           'pressure' in df_processed.columns and \\
    "           'flow_baseline' in df_processed.columns:\n",
    "            plot_event_for_labeling(i, event, \n",
    "                                    df_processed['flow_rate_filtered'], \n",
    "                                    df_processed['pressure'], # Using non-filtered pressure for plotting context\n",
    "                                    df_processed['flow_baseline'])\n",
    "            print(f\"  Plot saved for event {i}: {event['event_type']} starting at {event['event_start_time'].time()}\")\n",
    "        else:\n",
    "            print(f\"Skipping plot for event {i} due to missing processed data.\")\n",
    "    \n",
    "    # --- Apply Heuristic Rules (Example - TO BE REFINED BY USER) ---\n",
    "    # These are placeholders. Real rules would involve inspecting the plots and data characteristics.\n",
    "    for index, event in events_df.iterrows():\n",
    "        is_obstructive_like = False\n",
    "        is_central_like = False\n",
    "        \n",
    "        # Placeholder Rule 1: If apnea and very high reduction, lean central initially.\n",
    "        if event['event_type'] == 'apnea_candidate' and event['avg_flow_reduction_percent'] > 90:\n",
    "            is_central_like = True\n",
    "            \n",
    "        # Placeholder Rule 2: If hypopnea and moderate reduction, lean obstructive initially.\n",
    "        # This is a very weak heuristic without shape/pressure features.\n",
    "        if event['event_type'] == 'hypopnea_candidate' and event['avg_flow_reduction_percent'] > 40 and event['avg_flow_reduction_percent'] < 80:\n",
    "            is_obstructive_like = True \n",
    "        \n",
    "        # USER: Add more sophisticated rules here based on visual inspection of plots from your REAL data\n",
    "        # and potentially after looking at features from feature_engineering.py.\n",
    "        # Example: check pressure changes, flow limitation patterns, recovery breath shape etc.\n",
    "        # For instance, if 'df_processed' has 'flow_limitation' column:\n",
    "        # if 'flow_limitation' in df_processed.columns:\n",
    "        #     flow_lim_during_event = df_processed['flow_limitation'].loc[event['event_start_time']:event['event_end_time']].mean()\n",
    "        #     if flow_lim_during_event > some_threshold: is_obstructive_like = True\n",
    "\n",
    "        if is_obstructive_like and not is_central_like:\n",
    "            events_df.loc[index, 'heuristic_label'] = 'likely_obstructive'\n",
    "        elif is_central_like and not is_obstructive_like:\n",
    "            events_df.loc[index, 'heuristic_label'] = 'likely_central'\n",
    "        # else remains 'ambiguous'\n",
    "            \n",
    "    print(\"\\nEvents with heuristic labels (first few):\")\n",
    "    print(events_df[['event_start_time', 'event_type', 'heuristic_label']].head(10))\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(events_df['heuristic_label'].value_counts())\n",
    "\n",
    "    events_with_labels_path = '../data/events_with_heuristic_labels.csv'\n",
    "    if not events_df.empty:\n",
    "      events_df.to_csv(events_with_labels_path, index=False)\n",
    "      print(f\"\\nSaved events with heuristic labels to: {events_with_labels_path}\")\n",
    "    else:\n",
    "      print(\"\\nNo events to save.\")\n",
    "else:\n",
    "    print(\"Skipping heuristic labeling as no events were detected or previous steps failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Next Steps\n",
    "\n",
    "1.  **Refine Heuristic Labeling:** The rules above are very basic. For a real dataset, this step would involve more careful inspection of event plots and defining more robust rules, possibly incorporating features from `feature_engineering.py` in an iterative loop.\n",
    "2.  **Feature Engineering:** Proceed to the next notebook (`02_Feature_Engineering_and_Model_Training.ipynb`) to calculate detailed features for these labeled events.\n",
    "3.  **Model Training:** Train a classifier using the engineered features and these heuristic labels.\n",
    "4.  **Evaluation and Iteration:** Evaluate the model. If performance is insufficient, revisit heuristic labeling, feature engineering, or try different models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
