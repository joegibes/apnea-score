{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initial Data Exploration, Preprocessing, and Heuristic Labeling\n",
    "\n",
    "This notebook covers the initial steps of loading example CPAP data, performing preprocessing, detecting breaths and events, and then applying a heuristic (rule-based) labeling approach to a subset of events. This labeled subset will serve as the initial 'ground truth' for training our classification model.\n",
    "\n",
    "**Assumed File Structure:**\n",
    "```\n",
    "repository_root/\n",
    "├── data/                     # CPAP data CSVs will go here\n",
    "│   └── dummy_cpap_data.csv   # Example data file\n",
    "├── notebooks/\n",
    "│   └── 01_Initial_Data_Exploration_and_Labeling.ipynb\n",
    "├── src/\n",
    "│   ├── data_loader.py\n",
    "│   ├── preprocessing.py\n",
    "│   ├── breath_detection.py\n",
    "│   ├── event_detection.py\n",
    "│   └── feature_engineering.py\n",
    "│   └── classification_model.py\n",
    "└── results/\n",
    "    └── (plots, outputs will be saved here)\n",
    "```\n",
    "\n",
    "**Note:** This notebook uses placeholder data generation. In a real scenario, you would replace `generate_dummy_cpap_data_for_notebook` with actual data loading using `src.data_loader.load_cpap_data`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path to import modules\n",
    "module_path = os.path.abspath(os.path.join('..')) # Assumes notebook is in 'notebooks' directory\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data_loader import load_cpap_data, resample_data\n",
    "from src.preprocessing import butterworth_filter, flag_high_leak_periods, calculate_rolling_baseline\n",
    "from src.breath_detection import detect_breaths_from_flow\n",
    "from src.event_detection import detect_apneas_hypopneas\n",
    "from src.feature_engineering import extract_features_for_event\n",
    "\n",
    "# Configure plotting\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to generate dummy data for this notebook (mimicking OSCAR CSV structure)\n",
    "def generate_dummy_cpap_data_for_notebook(num_seconds=600, sampling_hz=25, filename=\"dummy_cpap_data.csv\"):\n",
    "    num_samples = num_seconds * sampling_hz\n",
    "    time_stamps = pd.to_datetime(np.arange(num_samples) / sampling_hz, unit='s')\n",
    "    \n",
    "    # Base flow simulating breathing\n",
    "    base_flow = 0.3 * np.sin(2 * np.pi * 0.25 * np.arange(num_samples) / sampling_hz) # 0.25 Hz = 15 bpm\n",
    "    base_flow += 0.05 * np.random.randn(num_samples) # Noise\n",
    "    \n",
    "    # Pressure (simple auto-adjust simulation)\n",
    "    pressure = 8 + 0.5 * np.sin(2 * np.pi * 0.01 * np.arange(num_samples) / sampling_hz) \n",
    "    pressure += 0.1 * np.random.randn(num_samples)\n",
    "\n",
    "    # Leak rate\n",
    "    leak_rate = 2.0 + np.abs(0.5 * np.random.randn(num_samples))\n",
    "    leak_rate[int(num_samples*0.4):int(num_samples*0.45)] = 25 # High leak period\n",
    "\n",
    "    # Simulate an obstructive-like event (flattened flow, pressure increase)\n",
    "    obs_start, obs_end = int(num_samples*0.2), int(num_samples*0.2) + 15*sampling_hz\n",
    "    base_flow[obs_start:obs_end] = 0.05 * np.sin(2 * np.pi * 0.2 * np.arange(obs_end-obs_start) / sampling_hz) + 0.02 # Low, flat\n",
    "    pressure[obs_start:obs_end+5*sampling_hz] += 2 # Pressure increases\n",
    "\n",
    "    # Simulate a central-like event (smooth cessation)\n",
    "    cen_start, cen_end = int(num_samples*0.6), int(num_samples*0.6) + 12*sampling_hz\n",
    "    for i in range(cen_start - 2*sampling_hz, cen_start):\n",
    "        base_flow[i] *= (cen_start - i) / (2*sampling_hz) # Fade out\n",
    "    base_flow[cen_start:cen_end] = 0.01 * np.random.randn(cen_end-cen_start) # Near zero\n",
    "    for i in range(cen_end, cen_end + 2*sampling_hz):\n",
    "        if i < num_samples:\n",
    "            base_flow[i] *= (i - cen_end) / (2*sampling_hz) # Fade in\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'Timestamp': time_stamps,\n",
    "        'FlowRate': base_flow,\n",
    "        'Pressure': pressure,\n",
    "        'LeakRate': leak_rate,\n",
    "        'MinuteVent': 6.0 + np.sin(2 * np.pi * 0.02 * np.arange(num_samples) / sampling_hz),\n",
    "        'RespRate': 15 + np.random.randn(num_samples),\n",
    "        'TidalVol': 0.4 + 0.05 * np.random.randn(num_samples)\n",
    "    })\n",
    "    \n",
    "    data_dir = '../data'\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    filepath = os.path.join(data_dir, filename)\n",
    "    df.to_csv(filepath, index=False)\n",
    "    print(f\"Generated dummy data at {filepath}\")\n",
    "    return filepath\n",
    "\n",
    "# Generate or specify path to your data file\n",
    "dummy_data_filepath = generate_dummy_cpap_data_for_notebook()\n",
    "# cpap_data_filepath = '../data/your_oscar_export.csv' # Replace with actual path\n",
    "cpap_data_filepath = dummy_data_filepath \n",
    "\n",
    "# Load data using the data_loader module\n",
    "raw_df = load_cpap_data(cpap_data_filepath,\n",
    "                          timestamp_col='Timestamp',\n",
    "                          flow_rate_col='FlowRate',\n",
    "                          pressure_col='Pressure',\n",
    "                          leak_rate_col='LeakRate',\n",
    "                          minute_vent_col='MinuteVent',\n",
    "                          resp_rate_col='RespRate',\n",
    "                          tidal_vol_col='TidalVol')\n",
    "\n",
    "if raw_df is not None:\n",
    "    print(\"Data loaded successfully:\")\n",
    "    raw_df.info()\n",
    "    raw_df.head()\n",
    "else:\n",
    "    print(\"Failed to load data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Data Resampling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLING_FREQ_HZ = 25 # Target sampling frequency\n",
    "\n",
    "if raw_df is not None:\n",
    "    df_resampled = resample_data(raw_df, target_freq_hz=SAMPLING_FREQ_HZ)\n",
    "    if df_resampled is not None:\n",
    "        print(f\"\\nResampled data to {SAMPLING_FREQ_HZ} Hz:\")\n",
    "        df_resampled.info()\n",
    "        \n",
    "        # Apply low-pass filter to flow rate\n",
    "        df_resampled['flow_rate_filtered'] = butterworth_filter(\n",
    "            df_resampled['flow_rate'], \n",
    "            filter_type='lowpass', \n",
    "            cutoff_freq_hz=2.0, # Cutoff to remove noise but keep breath shape\n",
    "            sampling_freq_hz=SAMPLING_FREQ_HZ\n",
    "        )\n",
    "        \n",
    "        # Flag high leak periods\n",
    "        df_resampled['high_leak'] = flag_high_leak_periods(\n",
    "            df_resampled['leak_rate'], \n",
    "            leak_threshold=20.0, # L/min, example threshold\n",
    "            min_duration_sec=10.0, \n",
    "            sampling_freq_hz=SAMPLING_FREQ_HZ\n",
    "        )\n",
    "        \n",
    "        # Calculate flow baseline (e.g., rolling median of filtered flow for amplitude)\n",
    "        # For event detection, baseline should reflect typical breath amplitude.\n",
    "        # Using a rolling median of absolute flow might be a simple proxy here.\n",
    "        df_resampled['flow_baseline'] = calculate_rolling_baseline(\n",
    "            df_resampled['flow_rate_filtered'].abs(), # Use absolute flow for amplitude baseline\n",
    "            window_sec=120, \n",
    "            sampling_freq_hz=SAMPLING_FREQ_HZ,\n",
    "            quantile=0.5 # Median\n",
    "        )\n",
    "        \n",
    "        print(\"\\nPreprocessed data head:\")\n",
    "        print(df_resampled[['flow_rate', 'flow_rate_filtered', 'flow_baseline', 'high_leak']].head())\n",
    "        \n",
    "        # Plot to verify\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        ax1 = plt.subplot(211)\n",
    "        df_resampled['flow_rate'].plot(label='Raw Flow', alpha=0.7, ax=ax1)\n",
    "        df_resampled['flow_rate_filtered'].plot(label='Filtered Flow', ax=ax1)\n",
    "        df_resampled['flow_baseline'].plot(label='Flow Baseline (Abs Median)', linestyle='--', ax=ax1)\n",
    "        ax1.set_title('Flow Data and Baseline')\n",
    "        ax1.legend()\n",
    "        \n",
    "        ax2 = plt.subplot(212, sharex=ax1)\n",
    "        df_resampled['leak_rate'].plot(label='Leak Rate', ax=ax2)\n",
    "        ax2.fill_between(df_resampled.index, 0, df_resampled['leak_rate'].max(), \n",
    "                         where=df_resampled['high_leak'], color='red', alpha=0.3, label='High Leak')\n",
    "        ax2.set_title('Leak Data')\n",
    "        ax2.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "    else:\n",
    "        print(\"Resampling failed.\")\n",
    "else:\n",
    "    print(\"Skipping preprocessing as data loading failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Breath and Event Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df_resampled' in locals() and df_resampled is not None:\n",
    "    # Breath Detection (optional for this notebook's main goal, but good for context)\n",
    "    # breaths_df = detect_breaths_from_flow(df_resampled['flow_rate_filtered'], \n",
    "    #                                       sampling_freq_hz=SAMPLING_FREQ_HZ)\n",
    "    # if not breaths_df.empty:\n",
    "    #     print(f\"\\nDetected {len(breaths_df)} breaths.\")\n",
    "    #     print(breaths_df.head())\n",
    "    # else:\n",
    "    #     print(\"No breaths detected.\")\n",
    "        \n",
    "    # Event Detection\n",
    "    events_df = detect_apneas_hypopneas(\n",
    "        flow_series=df_resampled['flow_rate_filtered'], # Use filtered flow\n",
    "        baseline_flow_series=df_resampled['flow_baseline'],\n",
    "        sampling_freq_hz=SAMPLING_FREQ_HZ,\n",
    "        apnea_threshold_ratio=0.1, # Flow < 10% of baseline\n",
    "        hypopnea_upper_threshold_ratio=0.7, # Flow < 70% of baseline (reduction >30%)\n",
    "        hypopnea_lower_threshold_ratio=0.1, # Flow > 10% of baseline (reduction <90%)\n",
    "        min_event_duration_s=10.0,\n",
    "        high_leak_flags=df_resampled['high_leak']\n",
    "    )\n",
    "    \n",
    "    if not events_df.empty:\n",
    "        print(f\"\\nDetected {len(events_df)} apnea/hypopnea candidate events:\")\n",
    "        print(events_df[['event_start_time', 'event_end_time', 'event_type', 'event_duration_s', 'avg_flow_reduction_percent', 'excluded_due_to_leak']])\n",
    "    else:\n",
    "        print(\"No apnea/hypopnea events detected.\")\n",
    "        events_df = pd.DataFrame() # Ensure it exists for later steps\n",
    "\n",
    "else:\n",
    "    print(\"Skipping event detection as preprocessing failed or was skipped.\")\n",
    "    events_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Heuristic Labeling of Events\n",
    "\n",
    "Now, we'll define some heuristic rules to assign initial labels ('likely_obstructive', 'likely_central', 'ambiguous') to the detected events. This requires visual inspection and domain knowledge. We'll create a helper function to plot events for inspection.\n",
    "\n",
    "**Heuristic Ideas (examples, needs refinement based on data):**\n",
    "*   **Likely Obstructive:**\n",
    "    *   Apnea/Hypopnea with significant flow flattening *before* or *during* (for hypopnea).\n",
    "    *   Sharp, large recovery breaths immediately following the event.\n",
    "    *   Associated with increased pressure from an auto-CPAP (if pressure data shows this clearly).\n",
    "    *   High variability in flow leading up to an apnea.\n",
    "*   **Likely Central:**\n",
    "    *   Smooth, tapered decrease and increase in flow for apneas.\n",
    "    *   Often part of a periodic breathing pattern (e.g., Cheyne-Stokes like waxing/waning flow over longer periods).\n",
    "    *   Hypopneas show proportional reduction in flow without significant shape change (inspiratory flow still rounded).\n",
    "    *   No significant auto-CPAP pressure increase specifically for the event.\n",
    "*   **Ambiguous:** Events that don't clearly fit either pattern or have conflicting features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_event_for_labeling(event_idx, event_series, flow_signal, pressure_signal, baseline_signal, window_s=30):\n",
    "    \"\"\"Plots flow and pressure around an event for manual inspection and labeling.\"\"\"\n",
    "    event_start = event_series['event_start_time']\n",
    "    event_end = event_series['event_end_time']\n",
    "    event_type = event_series['event_type']\n",
    "    \n",
    "    plot_start = event_start - pd.Timedelta(seconds=window_s)\n",
    "    plot_end = event_end + pd.Timedelta(seconds=window_s)\n",
    "    \n",
    "    plt.figure(figsize=(18, 7))\n",
    "    \n",
    "    # Flow Plot\n",
    "    ax1 = plt.subplot(211)\n",
    "    flow_signal.loc[plot_start:plot_end].plot(label='Flow', ax=ax1, color='cornflowerblue')\n",
    "    if baseline_signal is not None:\n",
    "         baseline_signal.loc[plot_start:plot_end].plot(label='Flow Baseline', linestyle='--', color='orange', ax=ax1)\n",
    "    ax1.axvspan(event_start, event_end, color='red', alpha=0.2, label=f'{event_type}')\n",
    "    ax1.set_title(f'Event {event_idx}: {event_type} ({event_series[\"event_duration_s\"]:.1f}s) | Start: {event_start.time()}')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "    \n",
    "    # Pressure Plot\n",
    "    ax2 = plt.subplot(212, sharex=ax1)\n",
    "    pressure_signal.loc[plot_start:plot_end].plot(label='Pressure', ax=ax2, color='green')\n",
    "    ax2.axvspan(event_start, event_end, color='red', alpha=0.2)\n",
    "    ax2.set_title('Pressure')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, which='both', linestyle=':', linewidth=0.5)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    # In a real interactive session, you might display this and then prompt for a label.\n",
    "    # For this notebook, we'll save it.\n",
    "    results_dir = '../results/event_plots_for_labeling'\n",
    "    if not os.path.exists(results_dir):\n",
    "        os.makedirs(results_dir)\n",
    "    plt.savefig(f\"{results_dir}/event_{event_idx}_{event_type.replace('_candidate','')}.png\")\n",
    "    plt.close() # Close to avoid too many plots in output if run for many events\n",
    "\n",
    "# Initialize a new column for heuristic labels\n",
    "if not events_df.empty:\n",
    "    events_df['heuristic_label'] = 'ambiguous' # Default to ambiguous\n",
    "    \n",
    "    print(\"\\nPlotting a few events for manual inspection (plots saved to results/event_plots_for_labeling/):\")\n",
    "    # Plot first few events as examples (up to 5, or fewer if not many events)\n",
    "    num_events_to_plot = min(len(events_df), 5)\n",
    "    for i in range(num_events_to_plot):\n",
    "        event = events_df.iloc[i]\n",
    "        plot_event_for_labeling(i, event, \n",
    "                                df_resampled['flow_rate_filtered'], \n",
    "                                df_resampled['pressure'],\n",
    "                                df_resampled['flow_baseline'])\n",
    "        print(f\"  Plot saved for event {i}: {event['event_type']} starting at {event['event_start_time'].time()}\")\n",
    "    \n",
    "    # --- Apply Heuristic Rules (Example) ---\n",
    "    # These rules are very basic and would need significant refinement based on real data patterns.\n",
    "    for index, event in events_df.iterrows():\n",
    "        # Get event context from full signal if needed for rules\n",
    "        # For simplicity, use pre-calculated event properties for now.\n",
    "        \n",
    "        is_obstructive_like = False\n",
    "        is_central_like = False\n",
    "        \n",
    "        # Rule 1: Very high flow reduction apneas are often central if not other obstructive signs\n",
    "        if event['event_type'] == 'apnea_candidate' and event['avg_flow_reduction_percent'] > 95:\n",
    "            is_central_like = True # Initial guess\n",
    "            \n",
    "        # Rule 2: Hypopneas with low flow reduction might be central if flow shape is normal\n",
    "        # (Requires flow shape features not yet calculated here, but placeholder for idea)\n",
    "        if event['event_type'] == 'hypopnea_candidate' and event['avg_flow_reduction_percent'] < 50:\n",
    "            is_central_like = True # Initial guess\n",
    "            \n",
    "        # Rule 3: Events with significant pressure increase during/after might be obstructive\n",
    "        # (Requires analyzing pressure signal around event - feature engineering step will do this)\n",
    "        # For now, using the dummy data's pressure change for the first event:\n",
    "        if index == 0 and event['event_type'] == 'hypopnea_candidate': # First event in dummy data is obstructive-like\n",
    "             is_obstructive_like = True\n",
    "             is_central_like = False # Override\n",
    "        \n",
    "        # Rule 4: Second event in dummy data is central-like apnea\n",
    "        if index == 1 and event['event_type'] == 'apnea_candidate':\n",
    "            is_central_like = True\n",
    "            is_obstructive_like = False\n",
    "\n",
    "        # Assign label based on heuristics\n",
    "        if is_obstructive_like and not is_central_like:\n",
    "            events_df.loc[index, 'heuristic_label'] = 'likely_obstructive'\n",
    "        elif is_central_like and not is_obstructive_like:\n",
    "            events_df.loc[index, 'heuristic_label'] = 'likely_central'\n",
    "        elif is_obstructive_like and is_central_like: # Conflicting, keep ambiguous\n",
    "            events_df.loc[index, 'heuristic_label'] = 'ambiguous'\n",
    "        else: # No strong indicators, keep ambiguous\n",
    "            events_df.loc[index, 'heuristic_label'] = 'ambiguous'\n",
    "            \n",
    "    print(\"\\nEvents with heuristic labels (first few):\")\n",
    "    print(events_df[['event_start_time', 'event_type', 'heuristic_label']].head(10))\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(events_df['heuristic_label'].value_counts())\n",
    "\n",
    "    # Save the events_df with heuristic labels for the next notebook (feature engineering)\n",
    "    events_with_labels_path = '../data/events_with_heuristic_labels.csv'\n",
    "    events_df.to_csv(events_with_labels_path, index=False)\n",
    "    print(f\"\\nSaved events with heuristic labels to: {events_with_labels_path}\")\n",
    "    \n",
    "else:\n",
    "    print(\"Skipping heuristic labeling as no events were detected or previous steps failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Next Steps\n",
    "\n",
    "1.  **Refine Heuristic Labeling:** The rules above are very basic. For a real dataset, this step would involve more careful inspection of event plots and defining more robust rules, possibly incorporating features from `feature_engineering.py` in an iterative loop.\n",
    "2.  **Feature Engineering:** Proceed to the next notebook (`02_Feature_Engineering_and_Model_Training.ipynb`) to calculate detailed features for these labeled events.\n",
    "3.  **Model Training:** Train a classifier using the engineered features and these heuristic labels.\n",
    "4.  **Evaluation and Iteration:** Evaluate the model. If performance is insufficient, revisit heuristic labeling, feature engineering, or try different models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
