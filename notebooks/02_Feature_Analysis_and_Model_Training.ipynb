{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Feature Analysis, Model Training, and Evaluation\n",
    "\n",
    "This notebook takes the events data (with heuristic labels from Notebook 1) and the full time-series CPAP data to:\n",
    "1.  Extract detailed features for each event using `src.feature_engineering`.\n",
    "2.  Analyze the engineered features.\n",
    "3.  Train a classification model using `src.classification_model`.\n",
    "4.  Evaluate the model's performance on our heuristically labeled data.\n",
    "5.  Discuss potential iterations and improvements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Setup and Data Loading\n",
    "\n",
    "Load preprocessed time-series data and the event data with heuristic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to Python path\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from src.data_loader import load_cpap_data, resample_data # For loading full signal\n",
    "from src.preprocessing import butterworth_filter, calculate_rolling_baseline # If re-running parts\n",
    "from src.feature_engineering import extract_features_for_event\n",
    "from src.classification_model import train_classification_model\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load the full time-series data (preprocessed if possible, or re-preprocess) ---\n",
    "# This assumes you have saved the resampled/preprocessed df from Notebook 1 or can reload raw and process.\n",
    "# For simplicity, we'll reload the dummy data and do minimal preprocessing again.\n",
    "\n",
    "DUMMY_DATA_FILENAME = \"dummy_cpap_data.csv\" # From Notebook 1\n",
    "cpap_data_filepath = f'../data/{DUMMY_DATA_FILENAME}'\n",
    "SAMPLING_FREQ_HZ = 25\n",
    "\n",
    "raw_cpap_df = load_cpap_data(cpap_data_filepath,\n",
    "                               timestamp_col='Timestamp',\n",
    "                               flow_rate_col='FlowRate',\n",
    "                               pressure_col='Pressure',\n",
    "                               leak_rate_col='LeakRate',\n",
    "                               # Optional cols if used by feature engineering directly\n",
    "                               minute_vent_col='MinuteVent',\n",
    "                               resp_rate_col='RespRate',\n",
    "                               tidal_vol_col='TidalVol'\n",
    "                              )\n",
    "\n",
    "if raw_cpap_df is None:\n",
    "    raise FileNotFoundError(f\"Ensure '{DUMMY_DATA_FILENAME}' exists in '../data/' from Notebook 1.\")\n",
    "\n",
    "full_signal_df = resample_data(raw_cpap_df, target_freq_hz=SAMPLING_FREQ_HZ)\n",
    "if full_signal_df is None:\n",
    "    raise ValueError(\"Failed to resample data.\")\n",
    "\n",
    "# Minimal preprocessing needed for feature engineering context\n",
    "full_signal_df['flow_rate_filtered'] = butterworth_filter(\n",
    "    full_signal_df['flow_rate'], 'lowpass', 2.0, SAMPLING_FREQ_HZ\n",
    ")\n",
    "full_signal_df['pressure_filtered'] = butterworth_filter(\n",
    "    full_signal_df['pressure'], 'lowpass', 1.0, SAMPLING_FREQ_HZ # Smooth pressure a bit\n",
    ")\n",
    "\n",
    "print(\"Full time-series signal data loaded and minimally processed.\")\n",
    "full_signal_df[['flow_rate_filtered', 'pressure_filtered']].info()\n",
    "\n",
    "# --- Load the events DataFrame with heuristic labels ---\n",
    "events_labeled_filepath = '../data/events_with_heuristic_labels.csv'\n",
    "try:\n",
    "    events_df = pd.read_csv(events_labeled_filepath,\n",
    "                            parse_dates=['event_start_time', 'event_end_time'])\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: '{events_labeled_filepath}' not found. Please run Notebook 1 first.\")\n",
    "    events_df = pd.DataFrame() # Assign empty to prevent further errors\n",
    "\n",
    "if not events_df.empty:\n",
    "    print(f\"\\nLoaded {len(events_df)} events with heuristic labels.\")\n",
    "    print(events_df[['event_start_time', 'event_type', 'heuristic_label']].head())\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(events_df['heuristic_label'].value_counts())\n",
    "else:\n",
    "    print(\"Event data is empty. Cannot proceed with feature engineering and model training.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Feature Engineering for Labeled Events\n",
    "\n",
    "Iterate through each labeled event and extract features using `extract_features_for_event`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_event_features_list = []\n",
    "if not events_df.empty and full_signal_df is not None:\n",
    "    for idx, event_row in events_df.iterrows():\n",
    "        # Ensure event_row.name is set for feature engineering function if it relies on it\n",
    "        event_row.name = idx \n",
    "        \n",
    "        # Extract features for this event\n",
    "        # Pass relevant signals from full_signal_df\n",
    "        current_event_features = extract_features_for_event(\n",
    "            event_row=event_row,\n",
    "            flow_series=full_signal_df['flow_rate_filtered'], \n",
    "            pressure_series=full_signal_df['pressure_filtered'],\n",
    "            sampling_freq_hz=SAMPLING_FREQ_HZ,\n",
    "            pre_event_window_s=30,\n",
    "            post_event_window_s=30\n",
    "        )\n",
    "        all_event_features_list.append(current_event_features)\n",
    "    \n",
    "    features_engineered_df = pd.DataFrame(all_event_features_list)\n",
    "    \n",
    "    # Merge heuristic labels back into the features dataframe\n",
    "    # `event_id` in features_engineered_df should correspond to the index of events_df\n",
    "    features_engineered_df = features_engineered_df.set_index('event_id')\n",
    "    features_engineered_df = features_engineered_df.join(events_df[['heuristic_label']])\n",
    "    \n",
    "    print(f\"\\nEngineered features for {len(features_engineered_df)} events.\")\n",
    "    print(features_engineered_df.head().T)\n",
    "    \n",
    "    # Save the engineered features\n",
    "    engineered_features_path = '../data/engineered_features_with_labels.csv'\n",
    "    features_engineered_df.to_csv(engineered_features_path)\n",
    "    print(f\"\\nSaved engineered features to: {engineered_features_path}\")\n",
    "else:\n",
    "    print(\"Skipping feature engineering as event data or signal data is missing.\")\n",
    "    features_engineered_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Feature Analysis (Basic)\n",
    "\n",
    "Let's look at some feature distributions across our heuristic labels. This can give clues about which features might be discriminative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not features_engineered_df.empty and 'heuristic_label' in features_engineered_df.columns:\n",
    "    # Select a few example features for visualization\n",
    "    # These names come from `feature_engineering.py` output\n",
    "    example_features_to_plot = [\n",
    "        'flow_during_abs_mean', \n",
    "        'pressure_rise_from_pre_to_during',\n",
    "        'hypopnea_flow_shape_flattening_idx',\n",
    "        'recovery_peak_flow_post5s',\n",
    "        'flow_pre_periodicity_lf_hf_ratio',\n",
    "        'flow_pre_coeff_var'\n",
    "    ]\n",
    "    \n",
    "    # Drop rows where heuristic_label is NaN if any (should be handled by model training too)\n",
    "    plot_df = features_engineered_df.dropna(subset=['heuristic_label'])\n",
    "    # Also, for some plots, drop rows where the feature itself is NaN to avoid errors\n",
    "\n",
    "    num_features_to_plot = len(example_features_to_plot)\n",
    "    plt.figure(figsize=(15, num_features_to_plot * 4))\n",
    "    for i, feature_name in enumerate(example_features_to_plot):\n",
    "        if feature_name not in plot_df.columns:\n",
    "            print(f\"Warning: Feature '{feature_name}' not found in DataFrame for plotting.\")\n",
    "            continue\n",
    "        \n",
    "        plt.subplot(num_features_to_plot, 1, i + 1)\n",
    "        # For violinplot, it's better to have non-NaN feature values\n",
    "        feature_plot_df = plot_df[[feature_name, 'heuristic_label']].dropna(subset=[feature_name])\n",
    "        if not feature_plot_df.empty:\n",
    "            sns.violinplot(x='heuristic_label', y=feature_name, data=feature_plot_df, \n",
    "                           order=['likely_central', 'ambiguous', 'likely_obstructive'])\n",
    "            plt.title(f'Distribution of {feature_name} by Heuristic Label')\n",
    "        else:\n",
    "            plt.text(0.5, 0.5, 'Not enough data for this feature/label combination', ha='center')\n",
    "            plt.title(f'{feature_name} (No Data)')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Correlation heatmap (on a subset of features to keep it readable)\n",
    "    numeric_cols = plot_df.select_dtypes(include=np.number).columns\n",
    "    # Select a subset of numeric_cols for heatmap if too many, e.g., first 15-20, or those plotted above\n",
    "    heatmap_features = [f for f in example_features_to_plot if f in numeric_cols]\n",
    "    if len(heatmap_features) > 1:\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        correlation_matrix = plot_df[heatmap_features].corr()\n",
    "        sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm', vmin=-1, vmax=1)\n",
    "        plt.title('Correlation Matrix of Selected Features')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Not enough numeric features selected for correlation heatmap.\")\n",
    "else:\n",
    "    print(\"Skipping feature analysis as engineered features or labels are missing.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Model Training and Evaluation\n",
    "\n",
    "Train a classifier using the engineered features and the heuristic labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not features_engineered_df.empty and 'heuristic_label' in features_engineered_df.columns:\n",
    "    # Drop events labeled as 'ambiguous' if we want a 2-class problem for initial model\n",
    "    # Or, treat 'ambiguous' as a third class if model supports it well / if desired.\n",
    "    # For this example, let's try to classify obstructive vs central, and exclude ambiguous for training.\n",
    "    trainable_df = features_engineered_df[features_engineered_df['heuristic_label'].isin(['likely_obstructive', 'likely_central'])]\n",
    "    \n",
    "    if len(trainable_df) > 10: # Need enough samples to train\n",
    "        print(f\"Training model on {len(trainable_df)} 'likely_obstructive' or 'likely_central' events.\")\n",
    "        \n",
    "        # Select model type\n",
    "        model_type_to_train = 'random_forest' # 'random_forest', 'logistic_regression', 'svm'\n",
    "        \n",
    "        trained_model_pipeline, test_predictions_df, metrics = train_classification_model(\n",
    "            features_df=trainable_df.copy(), # Pass a copy\n",
    "            target_column='heuristic_label',\n",
    "            model_type=model_type_to_train,\n",
    "            test_size=0.25, # Use 25% for test set\n",
    "            random_state=42,\n",
    "            n_folds=5 # 5-fold cross-validation on training part\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n--- {model_type_to_train} Model Evaluation Summary ---\")\n",
    "        print(f\"Test Set Accuracy: {metrics['accuracy']:.4f}\")\n",
    "        print(f\"Mean CV Accuracy on Training Data: {metrics['cv_mean_accuracy']:.4f} (std: {metrics['cv_std_accuracy']:.4f})\")\n",
    "        print(\"\\nTest Set Classification Report:\\n\", metrics['classification_report_str'])\n",
    "        print(\"\\nTest Set Confusion Matrix:\")\n",
    "        print(metrics['confusion_matrix_df'])\n",
    "        \n",
    "        # Display feature importances if it's a RandomForest model\n",
    "        if model_type_to_train == 'random_forest' and 'classifier' in trained_model_pipeline.named_steps:\n",
    "            rf_model = trained_model_pipeline.named_steps['classifier']\n",
    "            # Get feature names after imputation/scaling (if possible, depends on pipeline structure)\n",
    "            # For simplicity, assume column order is preserved or use original feature names from X_train\n",
    "            # Need to get feature names from the step before classifier\n",
    "            # This requires knowing the columns used for training (X used in train_classification_model)\n",
    "            \n",
    "            # Re-create the X that was used for training, to get column names\n",
    "            temp_X = trainable_df.drop(columns=['heuristic_label', 'event_id', \n",
    "                                                 'event_type_original', 'excluded_due_to_leak_original'], \n",
    "                                       errors='ignore')\n",
    "            numeric_features_used = temp_X.select_dtypes(include=np.number).columns.tolist()\n",
    "            \n",
    "            if hasattr(rf_model, 'feature_importances_') and numeric_features_used:\n",
    "                importances = rf_model.feature_importances_\n",
    "                feature_importance_df = pd.DataFrame({\n",
    "                    'feature': numeric_features_used,\n",
    "                    'importance': importances\n",
    "                }).sort_values(by='importance', ascending=False)\n",
    "                \n",
    "                plt.figure(figsize=(10, 8))\n",
    "                sns.barplot(x='importance', y='feature', data=feature_importance_df.head(20), palette='viridis')\n",
    "                plt.title('Top 20 Feature Importances (Random Forest)')\n",
    "                plt.tight_layout()\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"Could not retrieve feature importances for Random Forest.\")\n",
    "    else:\n",
    "        print(\"Not enough 'likely_obstructive' or 'likely_central' labeled events to train a model.\")\n",
    "else:\n",
    "    print(\"Skipping model training as feature data is missing or labels are not present.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Discussion and Next Steps\n",
    "\n",
    "The model's performance here is heavily dependent on the quality and quantity of the **heuristic labels** from Notebook 1. \n",
    "\n",
    "**Potential Next Steps for Iteration:**\n",
    "1.  **Refine Heuristic Labels:** \n",
    "    *   Go back to Notebook 1 (`01_Initial_Data_Exploration_and_Labeling.ipynb`).\n",
    "    *   Inspect more events, especially those misclassified by the current model (if predictions are available on the full dataset) or those where the model is uncertain.\n",
    "    *   Improve the heuristic rules. This might involve using some of the engineered features (e.g., if `flow_pre_periodicity_lf_hf_ratio` is high, it's more likely central).\n",
    "    *   Consider an active learning loop: train a model, use it to find the most uncertain samples, label those, and retrain.\n",
    "2.  **Feature Engineering & Selection:**\n",
    "    *   Are there other features that could be more discriminative? (e.g., more detailed breath-shape analysis from `breath_detection.py`, more sophisticated pressure change metrics).\n",
    "    *   Analyze feature importance (shown for Random Forest above). Are some features not contributing much or too correlated?\n",
    "    *   Consider dimensionality reduction (e.g., PCA) if there are very many features.\n",
    "3.  **Model Tuning:**\n",
    "    *   Try different model types (e.g., Gradient Boosting like XGBoost or LightGBM, which often perform well).\n",
    "    *   Perform hyperparameter tuning for the chosen model (e.g., using `GridSearchCV` or `RandomizedSearchCV` from scikit-learn).\n",
    "4.  **Address 'Ambiguous' Events:**\n",
    "    *   Decide on a strategy: \n",
    "        *   Keep them excluded from training a binary (obstructive/central) model.\n",
    "        *   Try to label them if patterns emerge.\n",
    "        *   Train a 3-class model (obstructive, central, ambiguous) if sufficient 'ambiguous' examples with consistent characteristics can be identified.\n",
    "        *   Use the binary model's probability scores: if probabilities for obstructive/central are both low (e.g., around 0.5), the model is uncertain, and the event could be flagged as ambiguous.\n",
    "5.  **Data Augmentation (if applicable and careful):** If one class is very underrepresented, explore techniques, but this is advanced and must be done cautiously to avoid unrealistic samples.\n",
    "6.  **External Validation:** Ultimately, validation against expert-scored Polysomnography (PSG) data would be needed to assess true clinical performance. The current evaluation is against our own heuristic labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
